{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 01:36:43.540394: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-29 01:36:43.632118: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-29 01:36:44.085552: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-29 01:36:44.086210: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-29 01:36:46.006961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearnex.model_selection import train_test_split\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "65m3Xc9l-EnO"
   },
   "outputs": [],
   "source": [
    "def eye_cropper(image_path):\n",
    "    frame = cv2.imread(image_path)  # Read the image using OpenCV\n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    facial_features_list = face_recognition.face_landmarks(gray)\n",
    "\n",
    "    try:\n",
    "        eye = facial_features_list[0]['left_eye']\n",
    "    except:\n",
    "        try:\n",
    "            eye = facial_features_list[0]['right_eye']\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    x_max = max([coordinate[0] for coordinate in eye])\n",
    "    x_min = min([coordinate[0] for coordinate in eye])\n",
    "    y_max = max([coordinate[1] for coordinate in eye])\n",
    "    y_min = min([coordinate[1] for coordinate in eye])\n",
    "\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "\n",
    "    if x_range > y_range:\n",
    "        right = round(.5 * x_range) + x_max\n",
    "        left = x_min - round(.5 * x_range)\n",
    "        bottom = round((((right - left) - y_range)) / 2) + y_max\n",
    "        top = y_min - round((((right - left) - y_range)) / 2)\n",
    "    else:\n",
    "        bottom = round(.5 * y_range) + y_max\n",
    "        top = y_min - round(.5 * y_range)\n",
    "        right = round((((bottom - top) - x_range)) / 2) + x_max\n",
    "        left = x_min - round((((bottom - top) - x_range)) / 2)\n",
    "\n",
    "    cropped = frame[top:(bottom + 1), left:(right + 1)]\n",
    "\n",
    "    cropped = cv2.resize(cropped, (80, 80))\n",
    "    image_for_prediction = cropped.reshape(-1, 80, 80, 3)\n",
    "\n",
    "    return image_for_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l62ZfgOZAStH",
    "outputId": "5567b08a-99f9-40d6-c52e-98d8da2c5a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesful Image Import Count = 500\n",
      "Succesful Image Import Count = 1000\n",
      "Succesful Image Import Count = 1500\n",
      "Succesful Image Import Count = 2000\n",
      "Succesful Image Import Count = 500\n",
      "Succesful Image Import Count = 1000\n",
      "Succesful Image Import Count = 1500\n",
      "Succesful Image Import Count = 2000\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(folder, eyes = 0):\n",
    "    count = 0\n",
    "    error_count = 0\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        try:\n",
    "            img = cv2.imread(os.path.join(folder,filename))\n",
    "            img = cv2.resize(img, (80,80)) ## Resizing the images\n",
    "            ## for eyes if it is 0: open, 1: close\n",
    "            images.append([img, eyes])\n",
    "        except:\n",
    "            error_count += 1\n",
    "            print('ErrorCount = ' + str(error_count))\n",
    "            continue\n",
    "        \n",
    "        count += 1\n",
    "        if count % 500 == 0:\n",
    "            print('Succesful Image Import Count = ' + str(count))\n",
    "\n",
    "    return images\n",
    "\n",
    "folder=\"./dataset/Open_Eyes\"\n",
    "open_eyes = load_images_from_folder(folder, 0)\n",
    "\n",
    "folder=\"./dataset/Closed_Eyes\"\n",
    "closed_eyes = load_images_from_folder(folder, 1)\n",
    "eyes = closed_eyes + open_eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m5K0wji8ASwi"
   },
   "outputs": [],
   "source": [
    "X = [] \n",
    "y = [] \n",
    "for features, label in eyes: \n",
    "     X.append(features)\n",
    "     y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7n5urpYl_Ofl"
   },
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, 80, 80, 3)\n",
    "y = np.array(y)\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eZs28CEQ_Oiu"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZXKRwY7_Ol0",
    "outputId": "3b546b97-631c-48cf-de99-b6dc12c95013"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "94/94 [==============================] - 4s 25ms/step - loss: 0.3387 - auc: 0.9254 - val_loss: 0.0928 - val_auc: 0.9954\n",
      "Epoch 2/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0850 - auc: 0.9922 - val_loss: 0.0383 - val_auc: 0.9985\n",
      "Epoch 3/24\n",
      "94/94 [==============================] - 2s 23ms/step - loss: 0.0365 - auc: 0.9988 - val_loss: 0.0400 - val_auc: 0.9980\n",
      "Epoch 4/24\n",
      "94/94 [==============================] - 2s 23ms/step - loss: 0.0681 - auc: 0.9940 - val_loss: 0.0320 - val_auc: 0.9994\n",
      "Epoch 5/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0396 - auc: 0.9973 - val_loss: 0.0692 - val_auc: 0.9969\n",
      "Epoch 6/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0470 - auc: 0.9970 - val_loss: 0.0251 - val_auc: 0.9992\n",
      "Epoch 7/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0201 - auc: 0.9994 - val_loss: 0.0108 - val_auc: 0.9999\n",
      "Epoch 8/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0060 - auc: 1.0000 - val_loss: 0.0115 - val_auc: 0.9994\n",
      "Epoch 9/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0240 - auc: 0.9981 - val_loss: 0.0121 - val_auc: 1.0000\n",
      "Epoch 10/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0102 - auc: 0.9997 - val_loss: 1.0210 - val_auc: 0.9567\n",
      "Epoch 11/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0760 - auc: 0.9926 - val_loss: 0.0346 - val_auc: 0.9986\n",
      "Epoch 12/24\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0829 - auc: 0.9932 - val_loss: 0.0400 - val_auc: 0.9977\n",
      "Epoch 13/24\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0161 - auc: 0.9997 - val_loss: 0.0130 - val_auc: 0.9994\n",
      "Epoch 14/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0033 - auc: 1.0000 - val_loss: 0.0119 - val_auc: 0.9994\n",
      "Epoch 15/24\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0046 - auc: 1.0000 - val_loss: 0.0583 - val_auc: 0.9975\n",
      "Epoch 16/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0285 - auc: 0.9987 - val_loss: 0.0131 - val_auc: 0.9994\n",
      "Epoch 17/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0502 - auc: 0.9970 - val_loss: 0.0494 - val_auc: 0.9963\n",
      "Epoch 18/24\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0117 - auc: 0.9992 - val_loss: 0.0150 - val_auc: 0.9994\n",
      "Epoch 19/24\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0023 - auc: 1.0000 - val_loss: 0.0088 - val_auc: 0.9994\n",
      "Epoch 20/24\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0052 - auc: 1.0000 - val_loss: 0.0180 - val_auc: 0.9994\n",
      "Epoch 21/24\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0037 - auc: 1.0000 - val_loss: 0.0091 - val_auc: 0.9994\n",
      "Epoch 22/24\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 3.6882e-04 - auc: 1.0000 - val_loss: 0.0115 - val_auc: 0.9994\n",
      "Epoch 23/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 2.7940e-04 - auc: 1.0000 - val_loss: 0.0088 - val_auc: 0.9994\n",
      "Epoch 24/24\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 5.4884e-04 - auc: 1.0000 - val_loss: 0.0147 - val_auc: 0.9994\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0147 - auc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.014726872555911541, 0.9993847608566284]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Adding first three convolutional layers\n",
    "model.add(Conv2D(\n",
    "                filters = 32, # number of filters\n",
    "                kernel_size = (3,3), # height/width of filter\n",
    "                activation = 'relu', # activation function \n",
    "                input_shape = (80,80,3) # shape of input (image)\n",
    "                ))\n",
    "model.add(Conv2D(\n",
    "                filters = 32, # number of filters\n",
    "                kernel_size = (3,3), # height/width of filter\n",
    "                activation = 'relu' # activation function \n",
    "                ))\n",
    "model.add(Conv2D(\n",
    "                filters = 32, # number of filters\n",
    "                kernel_size = (3,3), # height/width of filter\n",
    "                activation = 'relu' # activation function \n",
    "                ))\n",
    "\n",
    "# Adding pooling after convolutional layers\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) # Dimensions of the region that you are pooling\n",
    "\n",
    "# Adding second set of convolutional layers\n",
    "model.add(Conv2D(\n",
    "                filters = 32, # number of filters\n",
    "                kernel_size = (3,3), # height/width of filter\n",
    "                activation = 'relu' # activation function \n",
    "                ))\n",
    "model.add(Conv2D(\n",
    "                filters = 32, # number of filters\n",
    "                kernel_size = (3,3), # height/width of filter\n",
    "                activation = 'relu' # activation function \n",
    "                ))\n",
    "\n",
    "# Add last pooling layer.\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adding first dense layer with 256 nodes\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "# Adding a dropout layer to avoid overfitting\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3)) \n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# adding output layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# compiling the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=[tf.keras.metrics.AUC(curve = 'PR')])\n",
    "\n",
    "start = time()\n",
    "# fitting the model\n",
    "model.fit(X_train,\n",
    "            y_train,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=24)\n",
    "end = time()\n",
    "\n",
    "# evaluate the model \n",
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WjPNx8nO_Opc"
   },
   "outputs": [],
   "source": [
    "model.save('./dataset/drowsiness_detection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_responce(image, model):    \n",
    "    image_for_prediction = eye_cropper(image)\n",
    "    if image_for_prediction is None:\n",
    "        return 'Yes'\n",
    "    try:\n",
    "        image_for_prediction = image_for_prediction/255.0\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "    \n",
    "    prediction = model.predict(image_for_prediction)\n",
    "    print(prediction)\n",
    "    # Based on prediction, display either \"Open Eyes\" or \"Closed Eyes\"\n",
    "    if prediction < 0.7:\n",
    "        status = 'No'\n",
    "    else:\n",
    "        status = 'Yes'\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-29 01:40:05.502448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!python webcam.py"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
